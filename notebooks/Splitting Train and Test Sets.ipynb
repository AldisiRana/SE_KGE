{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Train and Test Sets based on clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The motive behind this experiment is to make sure our predictive model is not biased to the chemicals in the training set. So, what we will do here is use a list of chemicals clustered based on their similarities, find their neighbors, calculate their weight over the overall graph then use these weights to seperate training and test sets, in which a cluster of chemcials should only be in one of the sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataframe from csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import pybel\n",
    "import networkx as nx\n",
    "import os\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_chemicals = pd.read_csv(os.path.join(os.pardir, \"resources\", 'Clustered_chemicals.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting training and testing sets based on weighted clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_graph = pybel.from_pickle(os.path.join(os.pardir, \"resources\", \"fullgraph_with_chemsim.pickle\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_dict = {i : clustered_chemicals['PubchemID'].loc[clustered_chemicals['Cluster'] == i].tolist()\n",
    "                for i in range(1,clustered_chemicals.Cluster.nunique()+1)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we make lists of the chemicals in each clusters and their neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d67c4acb6da94b71a7ce6dce44246737",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1319), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "subgraphs_dict = {}\n",
    "for cluster, chemicals in tqdm(clusters_dict.items()):\n",
    "    chemicals_subgraph = []\n",
    "    for chemical in chemicals:\n",
    "        #formate chemical to BEL to match the nodes in full graph\n",
    "        chemical = pybel.dsl.Abundance(namespace='pubchem', name=str(chemical)) \n",
    "        #ignore chemicals not in the graph\n",
    "        if chemical not in full_graph.nodes():\n",
    "            continue\n",
    "        chemicals_subgraph.append(chemical)\n",
    "        for neighbor in full_graph.neighbors(chemical):\n",
    "            chemicals_subgraph.append(neighbor)\n",
    "        #ignore empty lists\n",
    "        if not chemicals_subgraph:\n",
    "            continue\n",
    "    subgraphs_dict[cluster] = list(dict.fromkeys(chemicals_subgraph)) # to remove duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we calculate the weights of each cluster by counting the number of edges in the subgraph and dividing it by the number of edges in the fullgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ea09092d4f941a2a6d9ac7f59bf8766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1319), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fullgraph_edges = len(full_graph.edges())\n",
    "cluster_weights = {}\n",
    "for cluster, nodes in tqdm(subgraphs_dict.items()):\n",
    "    subgraph = full_graph.subgraph(nodes)\n",
    "    edges = len(subgraph.edges())\n",
    "    cluster_weights[cluster] = edges/fullgraph_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create a csv file from the previous clusters file that contains the chemical, its cluster and its weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_chemicals['weight'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster, weight in cluster_weights.items():\n",
    "    clustered_chemicals.loc[clustered_chemicals['Cluster'] == cluster, 'weight'] = weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_chemicals.to_csv(os.path.join(os.pardir, \"resources\", 'clusters_weights.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an weighted edgelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_df = pd.read_csv(os.path.join(os.pardir, \"resources\",'clusters_weights.csv'), index_col=False, dtype={'PubchemID': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {}\n",
    "for index, row in weights_df.iterrows():\n",
    "    weights[pybel.dsl.Abundance(namespace='pubchem', name=row['PubchemID'])] = row['weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_df = pd.read_csv(os.path.join(os.pardir, \"resources\", 'fullgraph_nodes_mapping.tsv'), index_col=False, dtype={'NodeName': str, 'NodeNamespace':str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node_id</th>\n",
       "      <th>namespace</th>\n",
       "      <th>identifier</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>pubchem</td>\n",
       "      <td>85</td>\n",
       "      <td>(3-carboxy-2-hydroxypropyl)-trimethylazanium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>umls</td>\n",
       "      <td>C0000729</td>\n",
       "      <td>Abdominal cramps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>umls</td>\n",
       "      <td>C0000737</td>\n",
       "      <td>Abdominal pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>umls</td>\n",
       "      <td>C0687713</td>\n",
       "      <td>Gastrointestinal pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>umls</td>\n",
       "      <td>C0002418</td>\n",
       "      <td>Amblyopia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   node_id namespace identifier                                          name\n",
       "0        1   pubchem         85  (3-carboxy-2-hydroxypropyl)-trimethylazanium\n",
       "1        2      umls   C0000729                              Abdominal cramps\n",
       "2        3      umls   C0000737                                Abdominal pain\n",
       "3        4      umls   C0687713                         Gastrointestinal pain\n",
       "4        5      umls   C0002418                                     Amblyopia"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dict={}\n",
    "for index, row in mapping_df.iterrows():\n",
    "    if row['namespace'] == 'pubchem':\n",
    "        mapping_dict[pybel.dsl.Abundance(namespace=row['namespace'], name=row['identifier'])] = row['node_id']\n",
    "    elif row['namespace'] == 'umls':\n",
    "        mapping_dict[pybel.dsl.Pathology(namespace=row['namespace'], name=row['name'])] = row['node_id']\n",
    "    else:\n",
    "        mapping_dict[pybel.dsl.Protein(namespace=row['namespace'], name=row['identifier'])] = row['node_id']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(os.pardir, \"resources\", 'fullgraph_weighted.edgelist'),'w') as outputfile:\n",
    "    outputfile.write('Source\\tTarget\\tWeight\\n')\n",
    "    for source, target in full_graph.edges():\n",
    "        if source not in weights:\n",
    "            outputfile.write('%s\\t%s\\t%f\\n' %(mapping_dict[source], mapping_dict[target], 0.0))\n",
    "        else:\n",
    "            outputfile.write('%s\\t%s\\t%f\\n' %(mapping_dict[source], mapping_dict[target], weights[source]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_edgelist = pd.read_csv(os.path.join(os.pardir, \"resources\",'fullgraph_weighted.edgelist'), sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split training and testing sets based on weights (each weight corresponds to a cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inds, test_inds = next(GroupShuffleSplit(test_size=.40, n_splits=2, random_state = 7).split(weighted_edgelist, groups=weighted_edgelist['Weight']))\n",
    "\n",
    "training = weighted_edgelist.iloc[train_inds]\n",
    "testing = weighted_edgelist.iloc[test_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(os.path.join(os.pardir, \"resources\", 'training_edgelist.edgelist'), 'w') as trainingfile:\n",
    "    for index, row in training.iterrows():\n",
    "        trainingfile.write('%d\\t%d\\n' % (row['Source'], row['Target']))\n",
    "\n",
    "with open(os.path.join(os.pardir, \"resources\", 'testing_edgelist.edgelist'), 'w') as testingfile:\n",
    "    for index, row in testing.iterrows():\n",
    "        testingfile.write('%d\\t%d\\n' % (row['Source'], row['Target']))\n",
    "\n",
    "G_train = nx.read_edgelist(os.path.join(os.pardir, \"resources\",'training_edgelist.edgelist'))\n",
    "G_test = nx.read_edgelist(os.path.join(os.pardir, \"resources\",'testing_edgelist.edgelist'))\n",
    "for edge in G_test.edges():\n",
    "    if edge[0] not in G_train.nodes():\n",
    "        G_train.add_node(edge[0])\n",
    "        G_train.add_edge(edge[0], edge[1])\n",
    "    if edge[1] not in G_train.nodes():\n",
    "        G_train.add_node(edge[1])\n",
    "        G_train.add_edge(edge[0], edge[1])\n",
    "for edge in G_train.edges():\n",
    "    if edge in G_test.edges():\n",
    "        G_test.remove_edge(edge[0],edge[1])\n",
    "nx.write_edgelist(G_train, os.path.join(os.pardir, \"resources\",'training_edgelist.edgelist'), data = False)\n",
    "nx.write_edgelist(G_test, os.path.join(os.pardir, \"resources\",'testing_edgelist.edgelist'), data = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
